---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---
# Current Projects
## Research at Oklahoma State University, USA
* NSF Grant: NRI: Considerate Co-robot Intelligence through Ubiquitous Human State Awareness (NSF #1427345). My role: Research Assistant.
  * Robot-integrated Smart homes for elderly care
      * Designed and implemented a robot-integrated smart home (RiSH) testbed that consists of a home service robot, a home sensor network, a body sensor network, and a mobile device, cloud servers.
      * The RiSH testbed is employed in developing assistive technologies for the elderly who live independently at home.
  * Auditory learning for home service robots
      * Implemented an auditory perception platform for a home service robot that serves the elderly living alone at home. The robot is able to estimate the sound source position and recognize human speech in the room with multiple sound sources, as well as to collaborate with the caregiver on sound event recognition.
      * Developed context-aware sound event recognition for home service robots using a two-level dynamic Bayesian network (DBN) that models the intra-temporal and inter-temporal constraints among the context and sound events.
  * Companion Robots for elderly care
      * Designed and developed a companion robot for elderly care. The robot has capabilities to assist a older adult at home. It can work as an assistant to answer user’s questions through verbal conversation. It can take photos, record voice and video messages and then send them through emails or post on social networks. It is able to play game with the user. Moreover, It can give cognitive assessment, mood evaluation, health screening, pain evaluation, etc. It can also detect falls and make a video call to the caregiver for assistance.
  * Socio-emotional maintenance in aging with robotic technology (SMART)
      * Designed robotics functions for a field test to evaluate socio-emotional maintenance in aging with social robots. Thirty older adults completed a 40-minute interactive section. The robot enables to perform a series of social interactions with each participant (i.e., basic conversational behaviors, answering current time/weather, playing rock-paper-scissors, saying quotes/jokes, and playing music).     
  * Clinical screening interview using a social robot for geriatric care
      * Developed a framework that enables social robots to conduct regular clinical screening interviews in geriatric care, such as cognitive assessment, falls risk evaluation, pain rating, health screening, mood evaluation, companionship assessment, memory testing, fatigue, and short blessed testing. We developed a social robot with essential features to enable clinical screening interview, including a conversational interface, face tracking, an interaction handler, attention management, robot skills, and cloud service management. Besides, a general clinical screening interview model (GCIM) is proposed and implemented, which enables the robot to handle the whole interview process. 

# Past Projects
## Research at Oklahoma State University, USA
* NSF Grant: SHB: Type I (EXP): Context-aware Ubiquitous Human Health Monitoring (NSF #1231671). My role: Research Assistant.
  * Human-robot collaboration in a Mobile Visual Sensor Network
    * Developed a framework for human-robot collaboration in a Mobile Visual Sensor Network (MVSN). A collaborative architecture for the proposed human-integrated MVSN was developed to allow the human operator and robots to collaborate to perform surveillance tasks.
  * An Open Platform Telepresence Robot with Natural Human Interface
    * Developed an open platform telepresence robot, which uses an iRobot Create, ROS (Robot Operating System) and mobile devices. Besides using existing ROS packages we developed an Android application based on rosjava_core and android_core to control and view a live video stream from the remote robot. The robot could be used to have a video conference with people at a remote location. It is also equipped with capabilities such as autonomous navigation, hand-gesture recognition, and speech recognition through cloud computing services provided by Google.

## Research at Posts and Telecommunications Institute of Technology, Vietnam
* Design and Implementation of the Embedded System for Information Processing. *My role: Co-PI*.
  * Research project No. 01‐MN‐2009‐RD‐DT, funded by PTIT (Posts and Telecommunications Institute of Technology), Member of three‐member Team in charge of designing applications using FPGA and ARM9‐core MCU, 2009.

* Design and Implementation of the portable cable test instrument. *My role: Co-PI*.
  * Research project No. 05 ‐ TD ‐ 2007 ‐ RD ‐ DT, funded by VNPT (Vietnam Posts and Telecommunications Group), 2007.

* Design and Implementation of the CPLD/FPGA development Boards. *My role: PI*.
  * Research project No. 04 ‐ HV ‐ 2005 ‐ RD ‐ DT, funded by PTIT, 2005.

* Design and Implementation of the development Boards for 8051 Microcontroller Family. *My Role: PI*.
  * Research project No. 04  ‐ HV  ‐2004  ‐  RD  ‐  DT, funded by PTIT, 2004.

* Design and Implementation of the Electronics Circuit Experiment Boards driven by the Computer. *My role: PI*.
  * Research project No. 32 ‐ 2002 ‐ HV ‐ P – DT, funded by PTIT, 2002.

* Design and Implementation of the Internet Based Testing Software for Distance Training Centers of VNPT. *My Role: Senior Personnel*.
  * Research project No 222  ‐ 2000  ‐  TCT  ‐ AP  ‐ DT‐83, funded by VNPT, served as the project's QA person, inspected codes submitted by programming teams and ensured database’s integrity, 2001‐2002.
